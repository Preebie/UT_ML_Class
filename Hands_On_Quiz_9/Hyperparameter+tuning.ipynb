{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEf0c6yOq9Rh"
   },
   "source": [
    "## Context\n",
    "\n",
    "Banks incur significant losses due to default in loans. This has led to a tightening up of loan underwriting and has increased loan rejection rates. The need for a better credit risk scoring model is also raised by banks.\n",
    "\n",
    "The CNK bank has collected customer data for the past few years and wants to build a model to predict if a customer coming to purchase a loan is a good customer (will not default) or a bad customer (will default).\n",
    "\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "- month - the month of purchase\n",
    "- credit_amount - amount for which loan is requested\n",
    "- credit_term - for how long customer wants a loan\n",
    "- age - age of the customer\n",
    "- sex - gender of the customer\n",
    "- education - education level of customer\n",
    "- product_type - for purchasing what type of product does the customer need a loan (0, 1, 2, 3, 4)\n",
    "- having_children_flg - if the customer has children or not\n",
    "- region - customer region category(0, 1, 2)\n",
    "- income - income of the customer\n",
    "- family_status - another, married, unmarried\n",
    "- phone_operator - mobile operator category(0, 1, 2, 3)\n",
    "- is_client - if the customer wanting to purchase a loan is our client or not\n",
    "- target - 1-bad customer, 0-good customer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnxGmBkvq9Rj"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1914,
     "status": "ok",
     "timestamp": 1634811027211,
     "user": {
      "displayName": "Prof. Mukesh Rao",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02134472667302377777"
     },
     "user_tz": -330
    },
    "id": "UK2k3Mg-q9Rj"
   },
   "outputs": [],
   "source": [
    "# To help with reading and manipulation of data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To build a Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# To tune a model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# To get different performance metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# To suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhNJ3tawq9Rk"
   },
   "source": [
    "## Load and view dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a7ck33gHq9Rk",
    "outputId": "39ec123e-dc64-4741-ef22-279552efcae7"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Loanclients.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLoanclients.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Loanclients.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Loanclients.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRePnbBq5cJd",
    "outputId": "c89bf037-07c3-4213-c6ec-8075943ae91e"
   },
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fu9Ni_Kk5cJe",
    "outputId": "a201a7b2-1693-4a7c-e435-a28b090842e2"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XlCskF3Fq9Rl",
    "outputId": "484f2238-9b83-4ea8-ccb4-d9d9ec07db52"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XbFryla5cJe",
    "outputId": "2c58762b-d38b-4829-ab29-dfa52d6c445e"
   },
   "outputs": [],
   "source": [
    "# checking missing values in the data\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQHkb8_W5cJf"
   },
   "source": [
    "**The income variable has some missing values, we will impute them later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-g1iA3vkhIzq",
    "outputId": "cbee7bf4-d507-401e-a6fa-51b345edefeb"
   },
   "outputs": [],
   "source": [
    "\n",
    "data[\"region\"] = data[\"region\"].astype(\"category\")\n",
    "data[\"phone_operator\"] = data[\"phone_operator\"].astype(\"category\")\n",
    "data[\"product_type\"] = data[\"product_type\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIQWS7KuhIzr",
    "outputId": "db1357f0-93bd-4dd0-ebac-acb7e5f3ec20"
   },
   "outputs": [],
   "source": [
    "# checking the distribution of the target variable\n",
    "data[\"target\"].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZFkLVZphIzr"
   },
   "source": [
    "### Splitting the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82OTq1bvhIzs",
    "outputId": "71ed9f43-1b1a-4559-86a9-19b633b1f80e"
   },
   "outputs": [],
   "source": [
    "# separating the independent and dependent variables\n",
    "X = data.drop([\"target\"], axis=1)\n",
    "y = data[\"target\"]\n",
    "\n",
    "# creating dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJM5CvFOhIzs",
    "outputId": "ce058b90-9625-472b-9843-12f5c6c3f5bd"
   },
   "outputs": [],
   "source": [
    "# Splitting data into training, validation and test set:\n",
    "\n",
    "# first we split data into 2 parts, say temporary and test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=5, stratify=y\n",
    ")\n",
    "\n",
    "# then we split the temporary set into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=5, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oy7LQSmJ5cJg",
    "outputId": "8da0a126-77d4-4d1f-a1d5-b5c094830256"
   },
   "outputs": [],
   "source": [
    "# Let's impute the missing values\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "\n",
    "# fit the imputer on train data and transform the train data\n",
    "X_train[\"income\"] = imp_median.fit_transform(X_train[[\"income\"]])\n",
    "\n",
    "# transform the validation and test data using the imputer fit on train data\n",
    "X_val[\"income\"] = imp_median.transform(X_val[[\"income\"]])\n",
    "X_test[\"income\"] = imp_median.transform(X_test[[\"income\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCOMaaMGhIzs",
    "outputId": "3d712183-c0a4-49bf-cf47-501d6ac2c9e8"
   },
   "outputs": [],
   "source": [
    "# Checking class balance for whole data, train set, validation set, and test set\n",
    "\n",
    "print(\"Target value ratio in y\")\n",
    "print(y.value_counts(1))\n",
    "print(\"*\" * 80)\n",
    "print(\"Target value ratio in y_train\")\n",
    "print(y_train.value_counts(1))\n",
    "print(\"*\" * 80)\n",
    "print(\"Target value ratio in y_val\")\n",
    "print(y_val.value_counts(1))\n",
    "print(\"*\" * 80)\n",
    "print(\"Target value ratio in y_test\")\n",
    "print(y_test.value_counts(1))\n",
    "print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30jm_OXJat4G"
   },
   "source": [
    "## Model evaluation criterion\n",
    "\n",
    "\n",
    "**What does a bank want?**\n",
    "* A bank wants to minimize the loss - it can face 2 types of losses here: \n",
    "   * Whenever a bank lends money to a customer, they don't return it.\n",
    "   * A bank doesn't lend money to a customer thinking a customer will default but in reality, the customer won't - opportunity loss.\n",
    "\n",
    "**Which loss is greater ?**\n",
    "* Lending to a customer who wouldn't be able to pay back.\n",
    "\n",
    "**Since we want to reduce loan defaults we should use Recall as a metric of model evaluation instead of accuracy.**\n",
    "\n",
    "* Recall - It gives the ratio of True positives to Actual positives, so high Recall implies low false negatives, i.e. low chances of predicting a bad customer as a good customer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6alhuirsj1r"
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NGTaawdat4H"
   },
   "source": [
    "### Let's first build a model with default parameters and see it's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCOiPgwkat4H",
    "outputId": "544ce052-db54-4fb3-fd49-3f4802363c47"
   },
   "outputs": [],
   "source": [
    "# model without hyperparameter tuning\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "423qASgLat4H"
   },
   "source": [
    "#### Let's check model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wpmoqh8sat4I",
    "outputId": "c37e18bf-0167-4b9d-b6bd-64a70dd705ba"
   },
   "outputs": [],
   "source": [
    "# Checking recall score on train and validation set\n",
    "print(\"Recall on train and validation set\")\n",
    "print(recall_score(y_train, rf.predict(X_train)))\n",
    "print(recall_score(y_val, rf.predict(X_val)))\n",
    "print(\"\")\n",
    "\n",
    "# Checking Precision score on train and validation set\n",
    "print(\"Precision on train and validation set\")\n",
    "print(precision_score(y_train, rf.predict(X_train)))\n",
    "print(precision_score(y_val, rf.predict(X_val)))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Checking Accuracy score on train and validation set\n",
    "print(\"Accuracy on train and validation set\")\n",
    "print(accuracy_score(y_train, rf.predict(X_train)))\n",
    "print(accuracy_score(y_val, rf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pagBRSPPat4J"
   },
   "source": [
    "- The model is performing well on the train data but the performance on the validation data is very poor.\n",
    "- Let's see if we can improve it with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EptTvLbuat4J"
   },
   "source": [
    "## Grid Search CV\n",
    "* Hyperparameter tuning is also tricky in the sense that there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model, so we usually resort to experimentation. i.e we'll use Grid search\n",
    "* Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters. \n",
    "* It is an exhaustive search that is performed on the specific parameter values of a model.\n",
    "* The parameters of the estimator/model used to apply these methods are optimized by cross-validated grid-search over a parameter grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dlc9_NIat4J"
   },
   "source": [
    "- **How to know the hyperparameters available for an algorithm?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WWA0sEJat4K",
    "outputId": "20318780-a105-4723-a810-6b1db11f6a36"
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcOIKqp4at4K"
   },
   "source": [
    "- We can see the names of hyperparameters available and their default values. \n",
    "- We can choose which ones to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1634811095494,
     "user": {
      "displayName": "Prof. Mukesh Rao",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02134472667302377777"
     },
     "user_tz": -330
    },
    "id": "VnKFyRAwVAPn",
    "outputId": "b84e0df0-1c11-459c-d583-58c4f55a35ad"
   },
   "outputs": [],
   "source": [
    "print(np.arange(0.2, 0.7, 0.1))\n",
    "\n",
    "print(np.arange(5,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m5AtskSat4K"
   },
   "source": [
    "### Let's tune Random forest using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylfOoVr0at4K",
    "outputId": "ee1800b1-618e-4f3a-90fa-3d5c34eb8d24"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Choose the type of classifier. \n",
    "rf1 = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {\"n_estimators\": [150,200,250],\n",
    "    \"min_samples_leaf\": np.arange(5, 10),\n",
    "    \"max_features\": np.arange(0.2, 0.7, 0.1),\n",
    "    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n",
    "    \"class_weight\" : ['balanced', 'balanced_subsample'],\n",
    "    \"max_depth\":np.arange(3,4,5),\n",
    "    \"min_impurity_decrease\":[0.001, 0.002, 0.003]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf1, parameters, scoring=acc_scorer, cv=5, n_jobs= -1, verbose = 2)\n",
    "# verbose = 2 tells about the number of fits, which can give an idea of how long will the model take in tuning\n",
    "# n_jobs = -1 so that all CPU cores can be run parallelly to optimize the Search\n",
    "\n",
    "grid_obj = grid_obj.fit(X_valid, Y_valid)\n",
    "\n",
    "# Print the best combination of parameters\n",
    "grid_obj.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LpaXjDIat4K"
   },
   "source": [
    "#### Let's check the best CV score, for the obtained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVO8ak5Fat4L",
    "outputId": "881d0886-4817-4d1a-8fa7-db29e1c41e8d"
   },
   "outputs": [],
   "source": [
    "grid_obj.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUvVCFguat4L"
   },
   "source": [
    "#### Let's build a model with obtained best parameters\n",
    "- We are hard coding the hyperparameters separately so that we don't have to run the grid search again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "379_TUHWat4L",
    "outputId": "6c1b901c-1821-4751-c9ac-b6b87f961bb3"
   },
   "outputs": [],
   "source": [
    "# Set the clf to the best combination of parameters\n",
    "rf1_tuned = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    max_features=0.2,\n",
    "    max_samples=0.6000000000000001,\n",
    "    min_samples_leaf=5,\n",
    "    n_estimators=150,\n",
    "    max_depth=3,\n",
    "    random_state=1,\n",
    "    min_impurity_decrease=0.001,\n",
    ")\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "rf1_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGRlwqfuat4M"
   },
   "source": [
    "#### Let's check the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uwkw63nFat4M",
    "outputId": "f57a0146-5766-4c57-9421-1be71fdb3a22"
   },
   "outputs": [],
   "source": [
    "# Checking recall score on train and validation set\n",
    "print(\"Recall on train and validation set\")\n",
    "print(recall_score(y_train, rf1_tuned.predict(X_train)))\n",
    "print(recall_score(y_val, rf1_tuned.predict(X_val)))\n",
    "print(\"\")\n",
    "\n",
    "# Checking precision score on train and validation set\n",
    "print(\"Precision on train and validation set\")\n",
    "print(precision_score(y_train, rf1_tuned.predict(X_train)))\n",
    "print(precision_score(y_val, rf1_tuned.predict(X_val)))\n",
    "print(\"\")\n",
    "\n",
    "# Checking accuracy score on train and validation set\n",
    "print(\"Accuracy on train and validation set\")\n",
    "print(accuracy_score(y_train, rf1_tuned.predict(X_train)))\n",
    "print(accuracy_score(y_val, rf1_tuned.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBnd4W_Fat4N"
   },
   "source": [
    "- We can see improvement in validation performance as compared to the model without hyperparameter tuning\n",
    "- Recall on both training set and validation set is good and is 88% on the validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnujALXkat4O"
   },
   "source": [
    "## Randomized Search CV\n",
    "* Random search is a tuning technique that attempts to compute the optimum values of hyperparameters randomly unlike grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W11Pi8rlat4O"
   },
   "source": [
    "### Let's tune Random forest using Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4Lkjcefat4P",
    "outputId": "e146b028-0de1-46a5-ef44-fe418539dad3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Choose the type of classifier. \n",
    "rf2 = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {\"n_estimators\": [150,200,250],\n",
    "    \"min_samples_leaf\": np.arange(5, 10),\n",
    "    \"max_features\": np.arange(0.2, 0.7, 0.1), \n",
    "    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n",
    "    \"max_depth\":np.arange(3,4,5),\n",
    "    \"class_weight\" : ['balanced', 'balanced_subsample'],\n",
    "    \"min_impurity_decrease\":[0.001, 0.002, 0.003]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the random search\n",
    "grid_obj = RandomizedSearchCV(rf2, parameters,n_iter=30, scoring=acc_scorer,cv=5, random_state = 1, n_jobs = -1, verbose = 2)\n",
    "# using n_iter = 30, so randomized search will try 30 different combinations of hyperparameters\n",
    "# by default, n_iter = 10\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Print the best combination of parameters\n",
    "grid_obj.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BC3IB5JAat4P"
   },
   "source": [
    "#### Let's check the best CV score, for the obtained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HZAnjxfat4P",
    "outputId": "99fe8701-ae44-4905-c2f6-0c503aee1884"
   },
   "outputs": [],
   "source": [
    "grid_obj.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCFHwl5xat4P"
   },
   "source": [
    "#### Let's build a model with obtained best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8TWo6tTat4Q",
    "outputId": "d33dcf4c-0d32-4b82-ec89-9a4263d312a6"
   },
   "outputs": [],
   "source": [
    "# Set the clf to the best combination of parameters\n",
    "rf2_tuned = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    max_features=0.2,\n",
    "    max_samples=0.5,\n",
    "    min_samples_leaf=5,\n",
    "    n_estimators=150,\n",
    "    random_state=1,\n",
    "    max_depth=3,\n",
    "    min_impurity_decrease=0.003,\n",
    ")\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "rf2_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZZ8N0M4at4Q"
   },
   "source": [
    "- Different results from the grid and the random search\n",
    "- Randomised search might give better results than grid search for the same parameter grid because of the use of cross-validation as fold varies the scores also vary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSEY5KJ-at4Q"
   },
   "source": [
    "#### Let's check the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgGjmHayat4Q",
    "outputId": "2c276e16-5b6f-4e04-c3d8-16878a0f1670"
   },
   "outputs": [],
   "source": [
    "# Checking recall score on train and validation set\n",
    "print(\"Recall on train and validation set\")\n",
    "print(recall_score(y_train, rf2_tuned.predict(X_train)))\n",
    "print(recall_score(y_val, rf2_tuned.predict(X_val)))\n",
    "print(\"\")\n",
    "print(\"Precision on train and validation set\")\n",
    "# Checking precision score on train and validation set\n",
    "print(precision_score(y_train, rf2_tuned.predict(X_train)))\n",
    "print(precision_score(y_val, rf2_tuned.predict(X_val)))\n",
    "print(\"\")\n",
    "print(\"Accuracy on train and validation set\")\n",
    "# Checking accuracy score on train and validation set\n",
    "print(accuracy_score(y_train, rf2_tuned.predict(X_train)))\n",
    "print(accuracy_score(y_val, rf2_tuned.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebNJl1ZKat4R"
   },
   "source": [
    "- The model is performing better than model with default parameters and the performance is similar to the model we received with grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVeUUOVjat4R"
   },
   "source": [
    "#### Choose a best model and predict the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmBsx6I3at4R",
    "outputId": "21dff7fe-483f-4663-cdcc-7a3d0b86dd9f"
   },
   "outputs": [],
   "source": [
    "model = rf1_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wazimV7oat4R",
    "outputId": "5c5606f7-476a-4844-ca55-9079a98b92ab"
   },
   "outputs": [],
   "source": [
    "# Checking recall score on test set\n",
    "print(\"Recall on test set\")\n",
    "print(recall_score(y_test, model.predict(X_test)))\n",
    "print(\"\")\n",
    "\n",
    "# Checking precision score on test set\n",
    "print(\"Precision on test set\")\n",
    "print(precision_score(y_test, model.predict(X_test)))\n",
    "print(\"\")\n",
    "\n",
    "# Checking accuracy score on test set\n",
    "print(\"Accuracy on test set\")\n",
    "print(accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UO2wLc07at4R"
   },
   "source": [
    "- The performance is close to one we observed in the validation set, so there is no overfitting"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
