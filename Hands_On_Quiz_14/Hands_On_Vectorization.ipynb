{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proprietary content. ©Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: \n",
    "\n",
    "This notebook is an updated version of the notebook used in the **hands-on lecture**.\n",
    "\n",
    "The following changes have been made:\n",
    "\n",
    "1. A note has been added at the bottom regarding the TfidfVectorizer() from Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 12, 'is': 3, 'the': 10, 'first': 2, 'stage': 9, 'of': 5, 'qualification': 7, 'second': 8, 'and': 1, 'third': 11, 'one': 6, 'it': 4, 'again': 0}\n",
      "(4, 13)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0 0 1 1 0 1 0 1 0 1 1 0 1]\n",
      " [0 0 0 1 0 1 0 1 1 1 1 0 1]\n",
      " [0 1 0 0 0 0 1 0 0 0 1 1 0]\n",
      " [1 0 1 1 1 0 0 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# list of text documents\n",
    "text = text = ['This is the first stage of qualification'\n",
    ", 'This is the second stage of qualification '\n",
    ", 'And the third one'\n",
    ", 'Is it the first stage again']\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# encode another document\n",
    "text2 = [\"the puppy\"]\n",
    "vector = vectorizer.transform(text2)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 12, 'is': 3, 'the': 10, 'first': 2, 'stage': 9, 'of': 5, 'qualification': 7, 'second': 8, 'and': 1, 'third': 11, 'one': 6, 'it': 4, 'again': 0}\n",
      "[1.91629073 1.91629073 1.51082562 1.22314355 1.91629073 1.51082562\n",
      " 1.91629073 1.51082562 1.91629073 1.22314355 1.         1.91629073\n",
      " 1.51082562]\n",
      "(1, 13)\n",
      "[[0.         0.         0.41706663 0.33765138 0.         0.41706663\n",
      "  0.         0.41706663 0.         0.33765138 0.27605213 0.\n",
      "  0.41706663]]\n",
      "again\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "text = ['This is the first stage of qualification'\n",
    ", 'This is the second stage of qualification '\n",
    ", 'And the third one'\n",
    ", 'Is it the first stage again']\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# encode document\n",
    "vector = vectorizer.transform([text[0]])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())\n",
    "for x in (dict(zip(vectorizer.get_feature_names(), vector))):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please note:\n",
    "\n",
    "Sklearn's TfidfVectorizer() uses the IDF formula:\n",
    "\n",
    "idf(t) = log [ n / df(t) ] + 1\n",
    "\n",
    "where n is the total number of documents in the document set and df(t) is the document frequency of t; the document frequency is the number of documents in the document set that contain the term t. This is different from the standard textbook formula.  The effect of adding “1” to the IDF in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, will not be entirely ignored.\n",
    "\n",
    "Therefore you can observe that in the above code the IDF of the word \"the\" is 1 even though it is present in all documents and had to be zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
